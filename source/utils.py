"""
Common low level utility functions
"""
import logging
import sys
import warnings

import torch
import numpy as np
import yaml

from torch.utils.data.dataloader import DataLoader
from sklearn.manifold import TSNE

from source.autoencoders import *

def disable_warnings():
    """
    Disable printing of warnings

    Returns
    -------
    None
    """
    warnings.simplefilter("ignore")


def get_logger(name):
    """
    Return a logger for current module
    Returns
    -------

    logger : logger instance

    """
    logger = logging.getLogger(name)
    logger.setLevel(logging.DEBUG)
    formatter = logging.Formatter(fmt="%(asctime)s %(levelname)s %(name)s: %(message)s",
                                  datefmt="%Y-%m-%d - %H:%M:%S")
    console = logging.StreamHandler(sys.stdout)
    console.setLevel(logging.DEBUG)
    console.setFormatter(formatter)

    logger.addHandler(console)

    return logger


def accuracy_from_logits(target, logits, nclass=1):
    """
    Measure a classifier accuracy from its logits
    :param target: (B)
    :param logits: (B, 1)
    :return: accuracy
    """

    if nclass == 1:
        logits = logits.squeeze(1)
        ypred = (logits >= 0.0).float()
    else:
        ypred = torch.argmax(logits, -1)

    return torch.mean((target == ypred).float())


def conditional_error_rate_from_logits(logits, sensitive):
    """
    Compute the balance error rate (P(f=1|S=0) and P(f=0|S=1)) where f = sgn(logits)
    :param logits:
    :param sensitive:
    :return: P(f=1|S=0), P(f=0|S=1)
    """
    logits = logits.squeeze(1)
    ypred = (logits >= 0.0).float()

    p1 = ypred[(sensitive == 1) & (ypred == 0)].shape[0] / ypred[sensitive == 1].shape[0]
    p0 = ypred[(sensitive == 0) & (ypred == 1)].shape[0] / ypred[sensitive == 0].shape[0]

    return p0, p1


def positive_from_logits(logits, sensitive, y=None, eps=10**(-8)):
    """
    Compute (P(f=1|S=1) and P(f=1|S=0)) where f = sgn(logits)
    :param logits:
    :param sensitive:
    :return: P(f=1|S=1), P(f=1|S=0)
    """
    logits = logits.squeeze(1)
    ypred = (logits >= 0.0).float()

    if len(sensitive.shape) == 1:
        p1 = ypred[(sensitive == 1) & (ypred == 1)].shape[0] / ypred[sensitive == 1].shape[0]
        p0 = ypred[(sensitive == 0) & (ypred == 1)].shape[0] / ypred[sensitive == 0].shape[0]
    else:
        ypred = ypred[:, None]
        y = y[:, None]
        pi_s = torch.sum(sensitive, 0)
        pp1_s = torch.sum(sensitive * (1 - y), 0)
        pp0_s = torch.sum((1 - sensitive) * (1 - y))

        p0 = torch.sum(ypred * sensitive, 0) / (pi_s + eps)
        p1 = torch.sum(ypred * (1 - sensitive), 0) / (sensitive.shape[0] - pi_s + eps)

    if y is None:
        return p0, p1

    pp1 = torch.sum(ypred * sensitive * (1 - y), 0)
    pp0 = torch.sum(ypred * (1 - sensitive) * (1 - y), 0)
    np1 = torch.sum((1 - ypred) * sensitive * y, 0)
    np0 = torch.sum((1 - ypred) * (1 - sensitive) * y, 0)

    return p0, p1, pp1, pp0, np0, np1


def conditional_error_rate_from_densities(densities, sensitive):
    """
    Compute the balance error rate (P(f=1|S=0) and P(f=0|S=1)) where f is the
    plug-in classifier (see equation 13)
    :param densities: (2, B) densities[0, :] = P(Z|S=0), densities[1, :] = P(Z|S=1)
    :param sensitive:
    :return: P(f=1|S=0), P(f=0|S=1)
    """
    ypred = (densities[1, ...] - densities[0, ...] > 0).float()
    ypred = ypred.squeeze(-1)

    p1 = ypred[(sensitive == 1) & (ypred == 0)].shape[0] / ypred[sensitive == 1].shape[0]
    p0 = ypred[(sensitive == 0) & (ypred == 1)].shape[0] / ypred[sensitive == 0].shape[0]

    return p0, p1


def generate_tsne(config_file, checkpoints_list, dset, logger, balance=True):
    """
    Generate tsne for the representation generated by FBC
    :param config_file:
    :param checkpoints_list:
    :param dataloader:
    :return:
    """

    with open(config_file, 'r') as stream:
        config_dict = yaml.load(stream, Loader=yaml.SafeLoader)

    net_dict = config_dict['net']
    name_net = net_dict.pop('name')
    net_dict.pop('learning_rate')
    net = globals()[name_net].from_dict(config_dict['net'])

    dataloader = DataLoader(dset, batch_size=config_dict['batch_size'], shuffle=False)
    Z_list = []
    Y_list = []
    S_list = []

    for nrun, run in enumerate(checkpoints_list):
        z_list = []
        s_list = []
        y_list = []

        logger.info(f'Loading checkpoint {run}')
        checkpoint = torch.load(run, map_location='cpu')
        net.load_state_dict(checkpoint['model_state_dict'])

        for i, batch in enumerate(dataloader):
            s = batch['sensitive']
            y = batch['outcome']
            x = batch['input']

            z = net.encode(x)
            z = net.binarize(z).detach().numpy().reshape(s.shape[0], -1)

            if nrun > 0:
                z_list.append(z.reshape(s.shape[0], -1))
            else:
                z_list.append(x.reshape(s.shape[0], -1))

            s = torch.argmax(s, -1)
            s_list.append(s.numpy())

            y_list.append(y.numpy())

            if i > 20:
                break

        z = np.concatenate(z_list, axis=0)
        s = np.concatenate(s_list, axis=0)
        y = np.concatenate(y_list, axis=0)

        tsne = TSNE(n_components=2, verbose=1, perplexity=50, n_iter=1000, early_exaggeration=20, learning_rate=10)

        tsne_results = tsne.fit_transform(z)

        if balance:
            tsne_0 = tsne_results[s == 0, ...]
            tsne_1 = tsne_results[s == 1, ...]

            idx = np.random.choice(tsne_1.shape[0], tsne_0.shape[0], replace=False)

            tsne_1 = tsne_1[idx, ...]
            y0 = y[s == 0]
            y1 = y[s == 1]
            y1 = y1[idx]

            y = np.concatenate([y0, y1])
            tsne_results = np.concatenate([tsne_0, tsne_1])
            s = np.concatenate([np.zeros_like(y0), np.ones_like(y1)])

        S_list.append(s)
        Z_list.append(tsne_results)
        Y_list.append(y)

    return Z_list, S_list, Y_list
